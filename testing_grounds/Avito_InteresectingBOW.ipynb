{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using intersection BOW and difference BOW as features for Naive Bayes, SGD.\n",
    "\n",
    "#### Probabilities generated are then used as features for XGBoost later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_info = pd.read_csv('../ItemInfo_train.csv', encoding='utf-8', usecols=['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_clean = pd.read_csv('./ItemInfo_train5.csv', encoding='utf-8',usecols=['description_x_clean','description_y_clean'], converters={'description_x_clean':lambda x: x.strip(u'[]').split(', '),\n",
    "                                                                                                                                      'description_y_clean':lambda x: x.strip(u'[]').split(', ')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_pairs = pd.read_csv('../ItemPairs_train.csv', encoding='utf-8', usecols= ['itemID_1', 'itemID_2'])\n",
    "item_pairs.rename(columns={'itemID_1':'itemID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(item_info, item_pairs, on='itemID')\n",
    "item_info.rename(columns={'itemID': 'itemID_2'}, inplace=True)\n",
    "df = pd.merge(df, item_info, on='itemID_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df,desc_clean], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initial testing of 400 rows\n",
    "#df = df.loc[:400,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df.description_x_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df.description_x_clean[0]).intersection(set(df.description_y_clean[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering: intersecting bag of words\n",
    "def intersection_BOW(df):\n",
    "    x = df['description_x_clean']\n",
    "    y = df['description_y_clean']\n",
    "\n",
    "    return ' '.join(set(x).intersection(set(y))).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature engineering: Bag of words in either x or y but not both\n",
    "def sym_diff_BOW(df):\n",
    "    x = df['description_x_clean']\n",
    "    y = df['description_y_clean']\n",
    "    \n",
    "    return ' '.join(set(x).symmetric_difference(set(y))).split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['intersect_BOW'] = df[['description_x_clean','description_y_clean']].apply(intersection_BOW,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['sym_diff_BOW'] = df[['description_x_clean','description_y_clean']].apply(sym_diff_BOW,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>itemID_2</th>\n",
       "      <th>description_x_clean</th>\n",
       "      <th>description_y_clean</th>\n",
       "      <th>intersect_BOW</th>\n",
       "      <th>sym_diff_BOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4112648</td>\n",
       "      <td>[продам, камаз, 6520, 20, тонн]</td>\n",
       "      <td>[продам, камаз, 6520, 20, тонн]</td>\n",
       "      <td>[6520, камаз, продам, тонн, 20]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1991275</td>\n",
       "      <td>[тюнинге]</td>\n",
       "      <td>[тюнинге, возможен, торг]</td>\n",
       "      <td>[тюнинге]</td>\n",
       "      <td>[возможен, торг]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1223296</td>\n",
       "      <td>[телефон, хорошем, состоянии, трещин, сколов, ...</td>\n",
       "      <td>[отличном, состоянии, комплекте, зарядник, каб...</td>\n",
       "      <td>[состоянии, комплекте, кабель]</td>\n",
       "      <td>[работает, держит, лежит, зарядник, родное, ин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1058851</td>\n",
       "      <td>[отличный, подарок, новый, китайской, apple, н...</td>\n",
       "      <td>[отличный, подарок, новый, китайской, apple, н...</td>\n",
       "      <td>[245ггц, икпорт, мгц, использование, аккумулят...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2161930</td>\n",
       "      <td>[лыжные, ботинки, хорошем, состоянии, 34, размер]</td>\n",
       "      <td>[ботинки, 34, размер, хорошем, состоянии]</td>\n",
       "      <td>[ботинки, состоянии, размер, хорошем, 34]</td>\n",
       "      <td>[лыжные]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID  itemID_2                                description_x_clean  \\\n",
       "0       1   4112648                    [продам, камаз, 6520, 20, тонн]   \n",
       "1       3   1991275                                          [тюнинге]   \n",
       "2       4   1223296  [телефон, хорошем, состоянии, трещин, сколов, ...   \n",
       "3       7   1058851  [отличный, подарок, новый, китайской, apple, н...   \n",
       "4       8   2161930  [лыжные, ботинки, хорошем, состоянии, 34, размер]   \n",
       "\n",
       "                                 description_y_clean  \\\n",
       "0                    [продам, камаз, 6520, 20, тонн]   \n",
       "1                          [тюнинге, возможен, торг]   \n",
       "2  [отличном, состоянии, комплекте, зарядник, каб...   \n",
       "3  [отличный, подарок, новый, китайской, apple, н...   \n",
       "4          [ботинки, 34, размер, хорошем, состоянии]   \n",
       "\n",
       "                                       intersect_BOW  \\\n",
       "0                    [6520, камаз, продам, тонн, 20]   \n",
       "1                                          [тюнинге]   \n",
       "2                     [состоянии, комплекте, кабель]   \n",
       "3  [245ггц, икпорт, мгц, использование, аккумулят...   \n",
       "4          [ботинки, состоянии, размер, хорошем, 34]   \n",
       "\n",
       "                                        sym_diff_BOW  \n",
       "0                                                 []  \n",
       "1                                   [возможен, торг]  \n",
       "2  [работает, держит, лежит, зарядник, родное, ин...  \n",
       "3                                                 []  \n",
       "4                                           [лыжные]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('intersectingBOW.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for CountVectorizer and SGD:\n",
      "0.776050673548\n"
     ]
    }
   ],
   "source": [
    "print('Score for CountVectorizer and SGD:')\n",
    "print(cross_val_score(sgd_count, x, y, cv=6, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.isDuplicate\n",
    "x = df.intersect_BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "tfidf_vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_count = make_pipeline(count_vect, nb)\n",
    "nb_tfidf = make_pipeline(tfidf_vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TODO Run GridSearch to find best parameters for best model\n",
    " Compute for both intersection and difference \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_count.fit(x.loc[:50000,],y.loc[:50000,])\n",
    "fn = 'nb_count.sav'\n",
    "pickle.dump(nb_tfidf, open(fn), 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_tfidf.fit(x.loc[:50000,],y.loc[:50000,])\n",
    "fn = 'nb_tfidf.sav'\n",
    "pickle.dump(nb_tfidf, open(fn), 'wb')\n",
    "# Using this for feature\n",
    "#nb_tfidf.predict_proba(x.loc[350:,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scoring metrics\n",
    "scores= ['accuracy', 'precision', 'recall', 'roc_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for CountVectorizer and NB:\n",
      "0.827955809189\n",
      "0.8610410831\n",
      "0.880952852179\n",
      "0.878707482993\n"
     ]
    }
   ],
   "source": [
    "print('Score for CountVectorizer and NB:')\n",
    "# Accuracy: ratio of correctly predicted observation to total observations\n",
    "# TP+TN /TP+FP+TN+FN\n",
    "print(cross_val_score(nb_count, x, y, cv=6, scoring='accuracy').mean())\n",
    "\n",
    "# ROC_AUC: High TP, Low FP\n",
    "print(cross_val_score(nb_count, x, y, cv=6, scoring='roc_auc').mean())\n",
    "\n",
    "# Precision: TP/(TP+FP)\n",
    "# Of all passengers that labeled as survived, how many actually survived?\n",
    "print(cross_val_score(nb_count, x, y, cv=6, scoring='precision').mean())\n",
    "\n",
    "# Recall: TP/TP+FN\n",
    "#  Of all the passengers that truly survived, how many did we label?\n",
    "print(cross_val_score(nb_count, x, y, cv=6, scoring='recall').mean())\n",
    "\n",
    "# F1 score: weighted average of Precision and Recall\n",
    "# 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for tfidf and NB:\n",
      "0.805680820496\n",
      "0.852186430128\n"
     ]
    }
   ],
   "source": [
    "print('Score for tfidf and NB:')\n",
    "print(cross_val_score(nb_tfidf, x, y, cv=6, scoring='accuracy').mean())\n",
    "print(cross_val_score(nb_tfidf, x, y, cv=6, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_count = make_pipeline(count_vect, knn)\n",
    "knn_tfidf = make_pipeline(tfidf_vect, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for CountVectorizer and KNN:\n",
      "0.774150637188\n",
      "0.849362522787\n"
     ]
    }
   ],
   "source": [
    "print('Score for CountVectorizer and KNN:')\n",
    "print(cross_val_score(knn_count, x, y, cv=6, scoring='accuracy').mean())\n",
    "print(cross_val_score(knn_count, x, y, cv=6, scoring='roc_auc').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for l1 and KNN:\n",
      "0.771550003991\n"
     ]
    }
   ],
   "source": [
    "print('Score for tfidf and KNN:')\n",
    "print(cross_val_score(knn_tfidf, x, y, cv=6, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_count = make_pipeline(count_vect, sgd)\n",
    "sgd_tfidf = make_pipeline(tfidf_vect, sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for CountVectorizer and SGD:\n",
      "0.783516685734\n",
      "0.885251767374\n",
      "0.856796134743\n",
      "0.879319727891\n"
     ]
    }
   ],
   "source": [
    "print('Score for CountVectorizer and SGD:')\n",
    "print(cross_val_score(sgd_count, x, y, cv=6, scoring='accuracy').mean())\n",
    "print(cross_val_score(sgd_count, x, y, cv=6, scoring='roc_auc').mean())\n",
    "print(cross_val_score(sgd_count, x, y, cv=6, scoring='precision').mean())\n",
    "print(cross_val_score(sgd_count, x, y, cv=6, scoring='recall').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for TfidfVectorizer and SGD:\n",
      "0.771035641756\n"
     ]
    }
   ],
   "source": [
    "print('Score for TfidfVectorizer and SGD:')\n",
    "print(cross_val_score(sgd_tfidf, x, y, cv=6, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for GridSearch\n",
    "param_grid_nb ={'multinomialnb__alpha':[0,0.025,0.05,0.1,0.3]}\n",
    "param_grid_nb_tfidf = {'multinomialnb__alpha':[0,0.025,0.05,0.1,0.3]\n",
    "                       ,'tfidfvectorizer__norm':['l1','l2']\n",
    "                       ,'tfidfvectorizer__min_df':[0.0,0.03,0.1]\n",
    "                       ,'tfidfvectorizer__use_idf':[True,False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.py:699: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = (np.log(smoothed_fc) -\n",
      "/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.py:700: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(smoothed_cc.reshape(-1, 1)))\n",
      "/home/juan/anaconda2/lib/python2.7/site-packages/sklearn/naive_bayes.py:700: RuntimeWarning: invalid value encountered in subtract\n",
      "  np.log(smoothed_cc.reshape(-1, 1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783042394015\n",
      "{u'tfidfvectorizer__norm': u'l1', u'multinomialnb__alpha': 0.1, u'tfidfvectorizer__min_df': 0.0, u'tfidfvectorizer__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Tfidf Naive Bayes\n",
    "grid_nb_tfidf = GridSearchCV(nb_tfidf, param_grid_nb_tfidf, cv=5, scoring='accuracy')\n",
    "grid_nb_tfidf.fit(x,y)\n",
    "\n",
    "print(grid_nb_tfidf.best_score_)\n",
    "print(grid_nb_tfidf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 432 ms, sys: 4 ms, total: 436 ms\n",
      "Wall time: 512 ms\n",
      "0.765586034913\n",
      "{u'multinomialnb__alpha': 0.025}\n"
     ]
    }
   ],
   "source": [
    "grid_nb_count = GridSearchCV(nb_count, param_grid_nb, cv=5, scoring='accuracy')\n",
    "%time grid_nb_count.fit(x,y)\n",
    "\n",
    "print(grid_nb_count.best_score_)\n",
    "print(grid_nb_count.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753117206983\n",
      "{u'tfidfvectorizer__norm': u'l2', u'multinomialnb__alpha': 0.1, u'tfidfvectorizer__min_df': 0.0, u'tfidfvectorizer__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Tfidf Naive Bayes\n",
    "random_nb_tfidf = RandomizedSearchCV(nb_tfidf, param_grid_nb_tfidf, cv=5, scoring='accuracy', n_iter=5, random_state=1)\n",
    "random_nb_tfidf.fit(x,y)\n",
    "print(random_nb_tfidf.best_score_)\n",
    "print(random_nb_tfidf.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
